---
title: Uso de los progresos para expresar el relleno y el diseño de memoria
description: Los DirectML se describen mediante propiedades conocidas como los *tamaños* y los *progresos* de la tensores.
ms.custom: Windows 10 May 2019 Update
ms.localizationpriority: high
ms.topic: article
ms.date: 04/19/2019
ms.openlocfilehash: b944b1a2600febe27f209bffcc0e355c6a9fc7db
ms.sourcegitcommit: cba7f424a292fd7f3a8518947b9466439b455419
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 11/23/2019
ms.locfileid: "104549112"
---
# <a name="using-strides-to-express-padding-and-memory-layout"></a><span data-ttu-id="7f608-103">Uso de los progresos para expresar el relleno y el diseño de memoria</span><span class="sxs-lookup"><span data-stu-id="7f608-103">Using strides to express padding and memory layout</span></span>

<span data-ttu-id="7f608-104">Los DirectML &mdash; de los que están respaldados por los búferes de Direct3D 12 &mdash; se describen mediante propiedades conocidas como los *tamaños* y los *progresos* de la tensores.</span><span class="sxs-lookup"><span data-stu-id="7f608-104">DirectML tensors&mdash;which are are backed by Direct3D 12 buffers&mdash;are described by properties known as the *sizes* and the *strides* of the tensor.</span></span> <span data-ttu-id="7f608-105">Los *tamaños* de tensores describen las dimensiones lógicas de tensores.</span><span class="sxs-lookup"><span data-stu-id="7f608-105">The tensor's *sizes* describe the logical dimensions of the tensor.</span></span> <span data-ttu-id="7f608-106">Por ejemplo, un tensores 2D podría tener un alto de 2 y un ancho de 3.</span><span class="sxs-lookup"><span data-stu-id="7f608-106">For example, a 2D tensor might have a height of 2 and a width of 3.</span></span> <span data-ttu-id="7f608-107">Lógicamente, el tensores tiene 6 elementos distintos, aunque los tamaños no especifican cómo se almacenan dichos elementos en la memoria.</span><span class="sxs-lookup"><span data-stu-id="7f608-107">Logically, the tensor has 6 distinct elements, although the sizes don't specify how those elements are stored in memory.</span></span> <span data-ttu-id="7f608-108">Los *progresos* del tensores describen el diseño de memoria física de los elementos de tensores.</span><span class="sxs-lookup"><span data-stu-id="7f608-108">The tensor's *strides* describe the physical memory layout of the tensor's elements.</span></span>

## <a name="two-dimensional-2d-arrays"></a><span data-ttu-id="7f608-109">Matrices bidimensionales (2D)</span><span class="sxs-lookup"><span data-stu-id="7f608-109">Two-dimensional (2D) arrays</span></span>

<span data-ttu-id="7f608-110">Considere un tensores 2D que tenga un alto de 2 y un ancho de 3; los datos constan de caracteres de texto.</span><span class="sxs-lookup"><span data-stu-id="7f608-110">Consider a 2D tensor that has a height of 2 and a width of 3; the data comprises textual characters.</span></span> <span data-ttu-id="7f608-111">En C/C++, esto podría expresarse mediante una matriz multidimensional.</span><span class="sxs-lookup"><span data-stu-id="7f608-111">In C/C++, this might be expressed using a multi-dimensional array.</span></span>

```cpp
constexpr int rows = 2;
constexpr int columns = 3;
char tensor[rows][columns];
tensor[0][0] = 'A';
tensor[0][1] = 'B';
tensor[0][2] = 'C';
tensor[1][0] = 'D';
tensor[1][1] = 'E';
tensor[1][2] = 'F';
```

<span data-ttu-id="7f608-112">A continuación se muestra la vista lógica del tensores anterior.</span><span class="sxs-lookup"><span data-stu-id="7f608-112">The logical view of the above tensor is visualized below.</span></span>

```console
A B C
D E F
```

<span data-ttu-id="7f608-113">En C/C++, una matriz multidimensional se almacena en orden de fila principal.</span><span class="sxs-lookup"><span data-stu-id="7f608-113">In C/C++, a multi-dimensional array is stored in row-major order.</span></span> <span data-ttu-id="7f608-114">En otras palabras, los elementos consecutivos a lo largo de la dimensión de ancho se almacenan de forma contigua en el espacio de memoria lineal.</span><span class="sxs-lookup"><span data-stu-id="7f608-114">In other words, the consecutive elements along the width dimension are stored contiguously in linear memory space.</span></span>

<span data-ttu-id="7f608-115">Offset:</span><span class="sxs-lookup"><span data-stu-id="7f608-115">Offset:</span></span>|<span data-ttu-id="7f608-116">0</span><span class="sxs-lookup"><span data-stu-id="7f608-116">0</span></span>|<span data-ttu-id="7f608-117">1</span><span class="sxs-lookup"><span data-stu-id="7f608-117">1</span></span>|<span data-ttu-id="7f608-118">2</span><span class="sxs-lookup"><span data-stu-id="7f608-118">2</span></span>|<span data-ttu-id="7f608-119">3</span><span class="sxs-lookup"><span data-stu-id="7f608-119">3</span></span>|<span data-ttu-id="7f608-120">4</span><span class="sxs-lookup"><span data-stu-id="7f608-120">4</span></span>|<span data-ttu-id="7f608-121">5</span><span class="sxs-lookup"><span data-stu-id="7f608-121">5</span></span>
-|-|-|-|-|-|-
<span data-ttu-id="7f608-122">Valor:</span><span class="sxs-lookup"><span data-stu-id="7f608-122">Value:</span></span>|<span data-ttu-id="7f608-123">A</span><span class="sxs-lookup"><span data-stu-id="7f608-123">A</span></span>|<span data-ttu-id="7f608-124">B</span><span class="sxs-lookup"><span data-stu-id="7f608-124">B</span></span>|<span data-ttu-id="7f608-125">C</span><span class="sxs-lookup"><span data-stu-id="7f608-125">C</span></span>|<span data-ttu-id="7f608-126">D</span><span class="sxs-lookup"><span data-stu-id="7f608-126">D</span></span>|<span data-ttu-id="7f608-127">E</span><span class="sxs-lookup"><span data-stu-id="7f608-127">E</span></span>|<span data-ttu-id="7f608-128">F</span><span class="sxs-lookup"><span data-stu-id="7f608-128">F</span></span>

<span data-ttu-id="7f608-129">El *paso* de una dimensión es el número de elementos que se van a omitir para tener acceso al siguiente elemento de esa dimensión.</span><span class="sxs-lookup"><span data-stu-id="7f608-129">The *stride* of a dimension is the number of elements to skip in order to access the next element in that dimension.</span></span> <span data-ttu-id="7f608-130">Progresa el diseño de tensores en memoria.</span><span class="sxs-lookup"><span data-stu-id="7f608-130">Strides express the layout of the tensor in memory.</span></span> <span data-ttu-id="7f608-131">Con un orden de fila principal, el paso de la dimensión de ancho es siempre 1, ya que los elementos adyacentes a lo largo de la dimensión se almacenan de forma contigua.</span><span class="sxs-lookup"><span data-stu-id="7f608-131">With a row-major order, the stride of the width dimension is always 1, since adjacent elements along the dimension are stored contiguously.</span></span> <span data-ttu-id="7f608-132">El paso de la dimensión de alto depende del tamaño de la dimensión de ancho; en el ejemplo anterior, la distancia entre los elementos consecutivos a lo largo de la dimensión de alto (por ejemplo, a a D) es igual al ancho de tensores (que es 3 en este ejemplo).</span><span class="sxs-lookup"><span data-stu-id="7f608-132">The stride of the height dimension depends on the size of the width dimension; in the above example, the distance between consecutive elements along the height dimension (for example, A to D) is equal to the width of the tensor (which is 3 in this example).</span></span>

<span data-ttu-id="7f608-133">Para ilustrar un diseño diferente, considere el orden de la columna principal.</span><span class="sxs-lookup"><span data-stu-id="7f608-133">To illustrate a different layout, consider column-major order.</span></span> <span data-ttu-id="7f608-134">En otras palabras, los elementos consecutivos a lo largo de la dimensión de alto se almacenan de forma contigua en el espacio de memoria lineal.</span><span class="sxs-lookup"><span data-stu-id="7f608-134">In other words, the consecutive elements along the height dimension are stored contiguously in linear memory space.</span></span> <span data-ttu-id="7f608-135">En este caso, el ajuste de alto es siempre 1 y el intervalo de ancho es 2 (el tamaño de la dimensión de alto).</span><span class="sxs-lookup"><span data-stu-id="7f608-135">In this case, the height-stride is always 1, and the width-stride is 2 (the size of the height dimension).</span></span>

<span data-ttu-id="7f608-136">Offset:</span><span class="sxs-lookup"><span data-stu-id="7f608-136">Offset:</span></span>|<span data-ttu-id="7f608-137">0</span><span class="sxs-lookup"><span data-stu-id="7f608-137">0</span></span>|<span data-ttu-id="7f608-138">1</span><span class="sxs-lookup"><span data-stu-id="7f608-138">1</span></span>|<span data-ttu-id="7f608-139">2</span><span class="sxs-lookup"><span data-stu-id="7f608-139">2</span></span>|<span data-ttu-id="7f608-140">3</span><span class="sxs-lookup"><span data-stu-id="7f608-140">3</span></span>|<span data-ttu-id="7f608-141">4</span><span class="sxs-lookup"><span data-stu-id="7f608-141">4</span></span>|<span data-ttu-id="7f608-142">5</span><span class="sxs-lookup"><span data-stu-id="7f608-142">5</span></span>
-|-|-|-|-|-|-
<span data-ttu-id="7f608-143">Valor:</span><span class="sxs-lookup"><span data-stu-id="7f608-143">Value:</span></span>|<span data-ttu-id="7f608-144">A</span><span class="sxs-lookup"><span data-stu-id="7f608-144">A</span></span>|<span data-ttu-id="7f608-145">D</span><span class="sxs-lookup"><span data-stu-id="7f608-145">D</span></span>|<span data-ttu-id="7f608-146">B</span><span class="sxs-lookup"><span data-stu-id="7f608-146">B</span></span>|<span data-ttu-id="7f608-147">E</span><span class="sxs-lookup"><span data-stu-id="7f608-147">E</span></span>|<span data-ttu-id="7f608-148">C</span><span class="sxs-lookup"><span data-stu-id="7f608-148">C</span></span>|<span data-ttu-id="7f608-149">F</span><span class="sxs-lookup"><span data-stu-id="7f608-149">F</span></span>

## <a name="higher-dimensions"></a><span data-ttu-id="7f608-150">Dimensiones superiores</span><span class="sxs-lookup"><span data-stu-id="7f608-150">Higher dimensions</span></span>

<span data-ttu-id="7f608-151">Cuando llega a más de dos dimensiones, no es difícil hacer referencia a un diseño como fila principal o columna principal.</span><span class="sxs-lookup"><span data-stu-id="7f608-151">When it comes to greater than two dimensions, it's unwieldy to refer to a layout as either row-major or column-major.</span></span> <span data-ttu-id="7f608-152">Por lo tanto, en el resto de este tema se usan términos y etiquetas como estos.</span><span class="sxs-lookup"><span data-stu-id="7f608-152">So, the rest of this topic uses terms and labels such as these.</span></span>

- <span data-ttu-id="7f608-153">2D: &mdash; el alto de "HW" es la dimensión de orden superior (fila principal).</span><span class="sxs-lookup"><span data-stu-id="7f608-153">2D: "HW"&mdash;height is the highest-order dimension (row-major).</span></span>
- <span data-ttu-id="7f608-154">2D: el ancho "qu" &mdash; es la dimensión de orden superior (columna principal).</span><span class="sxs-lookup"><span data-stu-id="7f608-154">2D: "WH"&mdash;width is the highest-order dimension (column-major).</span></span>
- <span data-ttu-id="7f608-155">3D: la profundidad "DHW" &mdash; es la dimensión de orden superior, seguida de alto y ancho.</span><span class="sxs-lookup"><span data-stu-id="7f608-155">3D: "DHW"&mdash;depth is the highest-order dimension, followed by height, and then width.</span></span>
- <span data-ttu-id="7f608-156">3D: el ancho "WHD" &mdash; es la dimensión de orden superior, seguido de alto y luego profundidad.</span><span class="sxs-lookup"><span data-stu-id="7f608-156">3D: "WHD"&mdash;width is the highest-order dimension, followed by height, and then depth.</span></span>
- <span data-ttu-id="7f608-157">4D: "NCHW" &mdash; el número de imágenes (tamaño de lote), después el número de canales, el alto y el ancho.</span><span class="sxs-lookup"><span data-stu-id="7f608-157">4D: "NCHW"&mdash;the number of images (batch size), then the number of channels, then height, then width.</span></span>

<span data-ttu-id="7f608-158">En general, el paso *empaquetado* de una dimensión es igual al producto de los tamaños de las dimensiones de orden inferior.</span><span class="sxs-lookup"><span data-stu-id="7f608-158">In general, the *packed* stride of a dimension is equal to the product of the sizes of the lower-order dimensions.</span></span> <span data-ttu-id="7f608-159">Por ejemplo, con un diseño "DHW", el intervalo D es igual a H \* W; el intervalo H es igual a W; y el intervalo W es igual a 1.</span><span class="sxs-lookup"><span data-stu-id="7f608-159">For example, with a "DHW" layout, the D-stride is equal to H \* W; the H-stride is equal to W; and the W-stride is equal to 1.</span></span> <span data-ttu-id="7f608-160">Se dice que los progresos están *empaquetados* cuando el tamaño físico total del tensores es igual al tamaño lógico total del tensores; en otras palabras, no hay espacio adicional ni elementos superpuestos.</span><span class="sxs-lookup"><span data-stu-id="7f608-160">Strides are said to be *packed* when the total physical size of the tensor is equal to the total logical size of the tensor; in other words, there's no extra space nor overlapping elements.</span></span>

<span data-ttu-id="7f608-161">Vamos a ampliar el ejemplo de 2D a tres dimensiones, de modo que tengamos un tensores con profundidad 2, alto 2 y ancho 3 (para un total de 12 elementos lógicos).</span><span class="sxs-lookup"><span data-stu-id="7f608-161">Let's extend the 2D example to three dimensions, so that we have a tensor with depth 2, height 2, and width 3 (for a total of 12 logical elements).</span></span>

```console
A B C
D E F

G H I
J K L
```

<span data-ttu-id="7f608-162">Con un diseño "DHW", este tensores se almacena como se indica a continuación.</span><span class="sxs-lookup"><span data-stu-id="7f608-162">With a "DHW" layout, this tensor is stored as follows.</span></span>

<span data-ttu-id="7f608-163">Offset:</span><span class="sxs-lookup"><span data-stu-id="7f608-163">Offset:</span></span>|<span data-ttu-id="7f608-164">0</span><span class="sxs-lookup"><span data-stu-id="7f608-164">0</span></span>|<span data-ttu-id="7f608-165">1</span><span class="sxs-lookup"><span data-stu-id="7f608-165">1</span></span>|<span data-ttu-id="7f608-166">2</span><span class="sxs-lookup"><span data-stu-id="7f608-166">2</span></span>|<span data-ttu-id="7f608-167">3</span><span class="sxs-lookup"><span data-stu-id="7f608-167">3</span></span>|<span data-ttu-id="7f608-168">4</span><span class="sxs-lookup"><span data-stu-id="7f608-168">4</span></span>|<span data-ttu-id="7f608-169">5</span><span class="sxs-lookup"><span data-stu-id="7f608-169">5</span></span>|<span data-ttu-id="7f608-170">6</span><span class="sxs-lookup"><span data-stu-id="7f608-170">6</span></span>|<span data-ttu-id="7f608-171">7</span><span class="sxs-lookup"><span data-stu-id="7f608-171">7</span></span>|<span data-ttu-id="7f608-172">8</span><span class="sxs-lookup"><span data-stu-id="7f608-172">8</span></span>|<span data-ttu-id="7f608-173">9</span><span class="sxs-lookup"><span data-stu-id="7f608-173">9</span></span>|<span data-ttu-id="7f608-174">10</span><span class="sxs-lookup"><span data-stu-id="7f608-174">10</span></span>|<span data-ttu-id="7f608-175">11</span><span class="sxs-lookup"><span data-stu-id="7f608-175">11</span></span>|
-|-|-|-|-|-|-|-|-|-|-|-|-|
<span data-ttu-id="7f608-176">Valor:</span><span class="sxs-lookup"><span data-stu-id="7f608-176">Value:</span></span>|<span data-ttu-id="7f608-177">A</span><span class="sxs-lookup"><span data-stu-id="7f608-177">A</span></span>|<span data-ttu-id="7f608-178">B</span><span class="sxs-lookup"><span data-stu-id="7f608-178">B</span></span>|<span data-ttu-id="7f608-179">C</span><span class="sxs-lookup"><span data-stu-id="7f608-179">C</span></span>|<span data-ttu-id="7f608-180">D</span><span class="sxs-lookup"><span data-stu-id="7f608-180">D</span></span>|<span data-ttu-id="7f608-181">E</span><span class="sxs-lookup"><span data-stu-id="7f608-181">E</span></span>|<span data-ttu-id="7f608-182">F</span><span class="sxs-lookup"><span data-stu-id="7f608-182">F</span></span>|<span data-ttu-id="7f608-183">G</span><span class="sxs-lookup"><span data-stu-id="7f608-183">G</span></span>|<span data-ttu-id="7f608-184">H</span><span class="sxs-lookup"><span data-stu-id="7f608-184">H</span></span>|<span data-ttu-id="7f608-185">I</span><span class="sxs-lookup"><span data-stu-id="7f608-185">I</span></span>|<span data-ttu-id="7f608-186">J</span><span class="sxs-lookup"><span data-stu-id="7f608-186">J</span></span>|<span data-ttu-id="7f608-187">K</span><span class="sxs-lookup"><span data-stu-id="7f608-187">K</span></span>|<span data-ttu-id="7f608-188">L</span><span class="sxs-lookup"><span data-stu-id="7f608-188">L</span></span>|

- <span data-ttu-id="7f608-189">D-STRIDE = alto (2) \* ancho (3) = 6 (por ejemplo, la distancia entre ' A ' y ' G ').</span><span class="sxs-lookup"><span data-stu-id="7f608-189">D-stride = height (2) \* width (3) = 6 (for example, the distance between 'A' and 'G').</span></span>
- <span data-ttu-id="7f608-190">H-STRIDE = ancho (3) = 3 (por ejemplo, la distancia entre ' A ' y ' d ').</span><span class="sxs-lookup"><span data-stu-id="7f608-190">H-stride = width (3) = 3 (for example, the distance between 'A' and 'D').</span></span>
- <span data-ttu-id="7f608-191">W-STRIDE = 1 (por ejemplo, la distancia entre ' A ' y ' B ').</span><span class="sxs-lookup"><span data-stu-id="7f608-191">W-stride = 1 (for example, the distance between 'A' and 'B').</span></span>

<span data-ttu-id="7f608-192">El producto escalar de los índices/coordenadas de un elemento y los progresos proporciona el desplazamiento a ese elemento en el búfer.</span><span class="sxs-lookup"><span data-stu-id="7f608-192">The dot product of the indices/coordinates of an element and the strides provides the offset to that element in the buffer.</span></span> <span data-ttu-id="7f608-193">Por ejemplo, el desplazamiento del elemento H (d = 1, H = 0, w = 1) es 7.</span><span class="sxs-lookup"><span data-stu-id="7f608-193">For example, the offset of the H element (d=1, h=0, w=1) is 7.</span></span>

<span data-ttu-id="7f608-194">{1, 0, 1} ⋅ {6, 3, 1} = 1 \* 6 + 0 \* 3 + 1 \* 1 = 7</span><span class="sxs-lookup"><span data-stu-id="7f608-194">{1, 0, 1} ⋅ {6, 3, 1} = 1 \* 6 + 0 \* 3 + 1 \* 1 = 7</span></span>

## <a name="packed-tensors"></a><span data-ttu-id="7f608-195">Decenas empaquetados</span><span class="sxs-lookup"><span data-stu-id="7f608-195">Packed tensors</span></span>

<span data-ttu-id="7f608-196">En los ejemplos anteriores se ilustran los ampliadores *empaquetados* .</span><span class="sxs-lookup"><span data-stu-id="7f608-196">The examples above illustrate *packed* tensors.</span></span> <span data-ttu-id="7f608-197">Se dice que un tensores está *empaquetado* cuando el tamaño lógico de tensores (en elementos) es igual al tamaño físico del búfer (en elementos) y cada elemento tiene una dirección o desplazamiento único.</span><span class="sxs-lookup"><span data-stu-id="7f608-197">A tensor is said to be *packed* when the logical size of the tensor (in elements) is equal to the physical size of the buffer (in elements), and each element has a unique address/offset.</span></span> <span data-ttu-id="7f608-198">Por ejemplo, un 2x2x3 tensores se empaqueta si el búfer tiene 12 elementos de longitud y ningún par de elementos comparte el mismo desplazamiento en el búfer.</span><span class="sxs-lookup"><span data-stu-id="7f608-198">For example, a 2x2x3 tensor is packed if the buffer is 12 elements in length and no pair of elements share the same offset in the buffer.</span></span> <span data-ttu-id="7f608-199">Los diez empaquetados son el caso más común; pero los progresos permiten diseños de memoria más complejos.</span><span class="sxs-lookup"><span data-stu-id="7f608-199">Packed tensors are the most common case; but strides allow more complex memory layouts.</span></span>

## <a name="broadcasting-with-strides"></a><span data-ttu-id="7f608-200">Difusión con grandes progresos</span><span class="sxs-lookup"><span data-stu-id="7f608-200">Broadcasting with strides</span></span>

<span data-ttu-id="7f608-201">Si el tamaño de búfer de un tensores (en elementos) es menor que el del producto de sus dimensiones lógicas, entonces debe haber una superposición de elementos.</span><span class="sxs-lookup"><span data-stu-id="7f608-201">If a tensor's buffer size (in elements) is smaller than the product of its logical dimensions, then it follows that there must be some overlapping of elements.</span></span> <span data-ttu-id="7f608-202">El caso habitual de esto se conoce como *difusión*; donde los elementos de una dimensión son un duplicado de otra dimensión.</span><span class="sxs-lookup"><span data-stu-id="7f608-202">The usual case for this is known as *broadcasting*; where the elements of a dimension are a duplicate of another dimension.</span></span> <span data-ttu-id="7f608-203">Por ejemplo, volvamos a revisar el ejemplo de 2D.</span><span class="sxs-lookup"><span data-stu-id="7f608-203">For example, let's revisit the 2D example.</span></span> <span data-ttu-id="7f608-204">Supongamos que queremos un tensores lógico de 2x3, pero la segunda fila es idéntica a la primera fila.</span><span class="sxs-lookup"><span data-stu-id="7f608-204">Let's say that we want a tensor that is logically 2x3, but the second row is identical to the first row.</span></span> <span data-ttu-id="7f608-205">Este es el aspecto.</span><span class="sxs-lookup"><span data-stu-id="7f608-205">Here's how that looks.</span></span>

```console
A B C
A B C
```

<span data-ttu-id="7f608-206">Esto podría almacenarse como un tensores de HW/Row principal empaquetado.</span><span class="sxs-lookup"><span data-stu-id="7f608-206">This could be stored as a packed HW/row-major tensor.</span></span> <span data-ttu-id="7f608-207">Pero un almacenamiento más compacto solo incluiría 3 elementos (A, B y C) y usaría un valor de Height-STRIDE 0 en lugar de 3.</span><span class="sxs-lookup"><span data-stu-id="7f608-207">But a more compact storage would contain only 3 elements (A, B, and C) and use a height-stride of 0 instead of 3.</span></span> <span data-ttu-id="7f608-208">En este caso, el tamaño físico de la tensores es 3 elementos, pero el tamaño lógico es de 6 elementos.</span><span class="sxs-lookup"><span data-stu-id="7f608-208">In this case, the physical size of the tensor is 3 elements, but the logical size is 6 elements.</span></span>

<span data-ttu-id="7f608-209">En general, si el paso de una dimensión es 0, todos los elementos de las dimensiones de orden inferior se repiten a lo largo de la dimensión difundida; por ejemplo, si tensores es NCHW y el intervalo C es 0, cada canal tiene los mismos valores en H y W.</span><span class="sxs-lookup"><span data-stu-id="7f608-209">In general, if the stride of a dimension is 0, then all elements in the lower-order dimensions are repeated along the broadcasted dimension; for example, if the tensor is NCHW and the C-stride is 0, then each channel has the same values along H and W.</span></span>

## <a name="padding-with-strides"></a><span data-ttu-id="7f608-210">Relleno con grandes progresos</span><span class="sxs-lookup"><span data-stu-id="7f608-210">Padding with strides</span></span>

<span data-ttu-id="7f608-211">Se dice que un tensores está *rellenado* si su tamaño físico es mayor que el tamaño mínimo necesario para ajustarse a sus elementos.</span><span class="sxs-lookup"><span data-stu-id="7f608-211">A tensor is said to be *padded* if its physical size is larger than the minimum size needed to fit its elements.</span></span> <span data-ttu-id="7f608-212">Cuando no hay elementos de difusión ni superpuestos, el tamaño mínimo de tensores (en elementos) es simplemente el producto de sus dimensiones.</span><span class="sxs-lookup"><span data-stu-id="7f608-212">When there is no broadcasting nor overlapping elements, the minimum size of the tensor (in elements) is simply the product of its dimensions.</span></span> <span data-ttu-id="7f608-213">Puede usar la función auxiliar `DMLCalcBufferTensorSize` (consulte [funciones auxiliares de DirectML](dml-helper-functions.md) para obtener una lista de esa función) para calcular el tamaño de búfer *mínimo* para los diez DirectML.</span><span class="sxs-lookup"><span data-stu-id="7f608-213">You can use the helper function `DMLCalcBufferTensorSize` (see [DirectML helper functions](dml-helper-functions.md) for a listing of that function) to calculate the *minimum* buffer size for your DirectML tensors.</span></span>

<span data-ttu-id="7f608-214">Supongamos que un búfer contiene los siguientes valores (los elementos ' x ' indican valores de relleno).</span><span class="sxs-lookup"><span data-stu-id="7f608-214">Let's say that a buffer contains the following values (the 'x' elements indicate padding values).</span></span>

<span data-ttu-id="7f608-215">0</span><span class="sxs-lookup"><span data-stu-id="7f608-215">0</span></span>|<span data-ttu-id="7f608-216">1</span><span class="sxs-lookup"><span data-stu-id="7f608-216">1</span></span>|<span data-ttu-id="7f608-217">2</span><span class="sxs-lookup"><span data-stu-id="7f608-217">2</span></span>|<span data-ttu-id="7f608-218">3</span><span class="sxs-lookup"><span data-stu-id="7f608-218">3</span></span>|<span data-ttu-id="7f608-219">4</span><span class="sxs-lookup"><span data-stu-id="7f608-219">4</span></span>|<span data-ttu-id="7f608-220">5</span><span class="sxs-lookup"><span data-stu-id="7f608-220">5</span></span>|<span data-ttu-id="7f608-221">6</span><span class="sxs-lookup"><span data-stu-id="7f608-221">6</span></span>|<span data-ttu-id="7f608-222">7</span><span class="sxs-lookup"><span data-stu-id="7f608-222">7</span></span>|<span data-ttu-id="7f608-223">8</span><span class="sxs-lookup"><span data-stu-id="7f608-223">8</span></span>|<span data-ttu-id="7f608-224">9</span><span class="sxs-lookup"><span data-stu-id="7f608-224">9</span></span>|
-|-|-|-|-|-|-|-|-|-|
<span data-ttu-id="7f608-225">A</span><span class="sxs-lookup"><span data-stu-id="7f608-225">A</span></span>|<span data-ttu-id="7f608-226">B</span><span class="sxs-lookup"><span data-stu-id="7f608-226">B</span></span>|<span data-ttu-id="7f608-227">C</span><span class="sxs-lookup"><span data-stu-id="7f608-227">C</span></span>|<span data-ttu-id="7f608-228">x</span><span class="sxs-lookup"><span data-stu-id="7f608-228">x</span></span>|<span data-ttu-id="7f608-229">x</span><span class="sxs-lookup"><span data-stu-id="7f608-229">x</span></span>|<span data-ttu-id="7f608-230">D</span><span class="sxs-lookup"><span data-stu-id="7f608-230">D</span></span>|<span data-ttu-id="7f608-231">E</span><span class="sxs-lookup"><span data-stu-id="7f608-231">E</span></span>|<span data-ttu-id="7f608-232">F</span><span class="sxs-lookup"><span data-stu-id="7f608-232">F</span></span>|<span data-ttu-id="7f608-233">x</span><span class="sxs-lookup"><span data-stu-id="7f608-233">x</span></span>|<span data-ttu-id="7f608-234">x</span><span class="sxs-lookup"><span data-stu-id="7f608-234">x</span></span>

<span data-ttu-id="7f608-235">El tensores rellenado se puede describir mediante un alto-STRIDE 5 en lugar de 3.</span><span class="sxs-lookup"><span data-stu-id="7f608-235">The padded tensor can be described by using a height-stride of 5 instead of 3.</span></span> <span data-ttu-id="7f608-236">En lugar de recorrer 3 elementos para llegar a la siguiente fila, el paso es 5 elementos (3 elementos *reales* más 2 elementos de relleno).</span><span class="sxs-lookup"><span data-stu-id="7f608-236">Instead of stepping by 3 elements to get to the next row, the step is 5 elements (3 *real* elements plus 2 padding elements).</span></span> <span data-ttu-id="7f608-237">El relleno es habitual en los gráficos del equipo, por ejemplo, para asegurarse de que una imagen tiene una alineación de potencia de dos.</span><span class="sxs-lookup"><span data-stu-id="7f608-237">Padding is common in computer graphics, for example, to ensure that an image has a power-of-two alignment.</span></span>

```console
A B C
D E F
```

## <a name="directml-buffer-tensor-descriptions"></a><span data-ttu-id="7f608-238">Descripciones de tensores de búfer de DirectML</span><span class="sxs-lookup"><span data-stu-id="7f608-238">DirectML buffer tensor descriptions</span></span>

<span data-ttu-id="7f608-239">DirectML puede trabajar con diversos diseños de tensores físicos, ya que la estructura de [ **DML_BUFFER_TENSOR_DESC**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) tiene `Sizes` miembros y `Strides` .</span><span class="sxs-lookup"><span data-stu-id="7f608-239">DirectML can work with a variety of physical tensor layouts, since the [**DML_BUFFER_TENSOR_DESC** structure](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) has both `Sizes` and `Strides` members.</span></span> <span data-ttu-id="7f608-240">Algunas implementaciones de operador pueden ser más eficaces con un diseño específico, por lo que no es raro cambiar cómo se almacenan los datos de tensores para mejorar el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="7f608-240">Some operator implementations might be more efficient with a specific layout, so it's not uncommon to change how tensor data is stored for better performance.</span></span>

<span data-ttu-id="7f608-241">La mayoría de los operadores de DirectML requieren decenas o 5D, y el orden de los valores de los tamaños y los progresos es fijo.</span><span class="sxs-lookup"><span data-stu-id="7f608-241">Most DirectML operators require either 4D or 5D tensors, and the order of the sizes and strides values is fixed.</span></span> <span data-ttu-id="7f608-242">Al corregir el orden de los tamaños y los valores de STRIDE en una descripción de tensores, es posible que DirectML deduzca distintos diseños físicos.</span><span class="sxs-lookup"><span data-stu-id="7f608-242">By fixing the order of the sizes and stride values in a tensor description, it's possible for DirectML to infer different physical layouts.</span></span>

<span data-ttu-id="7f608-243">**4D**</span><span class="sxs-lookup"><span data-stu-id="7f608-243">**4D**</span></span>
- <span data-ttu-id="7f608-244">[**DML_BUFFER_TENSOR_DESC:: Sizes**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = {N-size, C-size, H-size, W-size}</span><span class="sxs-lookup"><span data-stu-id="7f608-244">[**DML_BUFFER_TENSOR_DESC::Sizes**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = { N-size, C-size, H-size, W-size }</span></span>
- <span data-ttu-id="7f608-245">[**DML_BUFFER_TENSOR_DESC:: progresos**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = {N-STRIDE, C-STRIDE, H-STRIDE, W-STRIDE}</span><span class="sxs-lookup"><span data-stu-id="7f608-245">[**DML_BUFFER_TENSOR_DESC::Strides**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = { N-stride, C-stride, H-stride, W-stride }</span></span>

<span data-ttu-id="7f608-246">**1]5D**</span><span class="sxs-lookup"><span data-stu-id="7f608-246">**5D**</span></span>
- <span data-ttu-id="7f608-247">**DML_BUFFER_TENSOR_DESC:: Sizes** = {N-size, C-size, D-size, H-size, W-size}</span><span class="sxs-lookup"><span data-stu-id="7f608-247">**DML_BUFFER_TENSOR_DESC::Sizes** = { N-size, C-size, D-size, H-size, W-size }</span></span>
- <span data-ttu-id="7f608-248">**DML_BUFFER_TENSOR_DESC::** saaltos = {N-STRIDE, C-STRIDE, D-STRIDE, H-STRIDE, W-STRIDE}</span><span class="sxs-lookup"><span data-stu-id="7f608-248">**DML_BUFFER_TENSOR_DESC::Strides** = { N-stride, C-stride, D-stride, H-stride, W-stride }</span></span>

<span data-ttu-id="7f608-249">Si un operador DirectML requiere 4D o un tensores, pero los datos reales tienen un rango más pequeño (por ejemplo, 2D), las dimensiones iniciales se deben rellenar con 1.</span><span class="sxs-lookup"><span data-stu-id="7f608-249">If a DirectML operator requires a 4D or a 5D tensor, but the actual data has a smaller rank (for example, 2D), then the leading dimensions should be filled with 1s.</span></span> <span data-ttu-id="7f608-250">Por ejemplo, un tensores "HW" se establece mediante **DML_BUFFER_TENSOR_DESC:: Sizes** = {1, 1, H, W}.</span><span class="sxs-lookup"><span data-stu-id="7f608-250">For example, an "HW" tensor is set using **DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, H, W }.</span></span>

<span data-ttu-id="7f608-251">Si los datos de tensores se almacenan en NCHW/NCDHW, no es necesario establecer **DML_BUFFER_TENSOR_DESC:: progresa**, a menos que quiera difundir o rellenar.</span><span class="sxs-lookup"><span data-stu-id="7f608-251">If tensor data is stored in NCHW/NCDHW, then it's not necessary to set **DML_BUFFER_TENSOR_DESC::Strides**, unless you want broadcasting or padding.</span></span> <span data-ttu-id="7f608-252">Puede establecer el campo progresa en `nullptr` .</span><span class="sxs-lookup"><span data-stu-id="7f608-252">You can set the strides field to `nullptr`.</span></span> <span data-ttu-id="7f608-253">Sin embargo, si los datos de tensores se almacenan en otro diseño, como NHWC, deberá progresar para expresar la transformación de NCHW a ese diseño.</span><span class="sxs-lookup"><span data-stu-id="7f608-253">However, if the tensor data is stored in another layout, such as NHWC, then you need strides in order to express the transformation from NCHW to that layout.</span></span>

<span data-ttu-id="7f608-254">Para ver un ejemplo sencillo, considere la descripción de un tensores 2D con el alto 3 y el ancho 5.</span><span class="sxs-lookup"><span data-stu-id="7f608-254">For a simple example, consider the description of a 2D tensor with height 3 and width 5.</span></span>

<span data-ttu-id="7f608-255">**NCHW empaquetado (avances implícitos)**</span><span class="sxs-lookup"><span data-stu-id="7f608-255">**Packed NCHW (implicit strides)**</span></span>
- <span data-ttu-id="7f608-256">**DML_BUFFER_TENSOR_DESC:: Sizes** = {1, 1, 3, 5}</span><span class="sxs-lookup"><span data-stu-id="7f608-256">**DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, 3, 5 }</span></span>
- <span data-ttu-id="7f608-257">**DML_BUFFER_TENSOR_DESC:: progresos** = `nullptr`</span><span class="sxs-lookup"><span data-stu-id="7f608-257">**DML_BUFFER_TENSOR_DESC::Strides** = `nullptr`</span></span>

<span data-ttu-id="7f608-258">**NCHW empaquetado (los progresos explícitos)**</span><span class="sxs-lookup"><span data-stu-id="7f608-258">**Packed NCHW (explicit strides)**</span></span>
- <span data-ttu-id="7f608-259">N-STRIDE = C-size \* H-size \* W-size = 1 \* 3 \* 5 = 15</span><span class="sxs-lookup"><span data-stu-id="7f608-259">N-stride = C-size \* H-size \* W-size = 1 \* 3 \* 5 = 15</span></span>
- <span data-ttu-id="7f608-260">C-STRIDE = H-size \* W-size = 3 \* 5 = 15</span><span class="sxs-lookup"><span data-stu-id="7f608-260">C-stride = H-size \* W-size = 3 \* 5 = 15</span></span>
- <span data-ttu-id="7f608-261">H-STRIDE = W-size = 5</span><span class="sxs-lookup"><span data-stu-id="7f608-261">H-stride = W-size = 5</span></span>
- <span data-ttu-id="7f608-262">W-STRIDE = 1</span><span class="sxs-lookup"><span data-stu-id="7f608-262">W-stride = 1</span></span>
- <span data-ttu-id="7f608-263">**DML_BUFFER_TENSOR_DESC:: Sizes** = {1, 1, 3, 5}</span><span class="sxs-lookup"><span data-stu-id="7f608-263">**DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, 3, 5 }</span></span>
- <span data-ttu-id="7f608-264">**DML_BUFFER_TENSOR_DESC:: progresos** = {15, 15, 5, 1}</span><span class="sxs-lookup"><span data-stu-id="7f608-264">**DML_BUFFER_TENSOR_DESC::Strides** = { 15, 15, 5, 1 }</span></span>

<span data-ttu-id="7f608-265">**NHWC empaquetado**</span><span class="sxs-lookup"><span data-stu-id="7f608-265">**Packed NHWC**</span></span>
- <span data-ttu-id="7f608-266">N-STRIDE = H-size \* W-Size \* C-size = 3 \* 5 \* 1 = 15</span><span class="sxs-lookup"><span data-stu-id="7f608-266">N-stride = H-size \* W-size \* C-size = 3 \* 5 \* 1 = 15</span></span>
- <span data-ttu-id="7f608-267">H-STRIDE = W-Size \* C-size = 5 \* 1 = 5</span><span class="sxs-lookup"><span data-stu-id="7f608-267">H-stride = W-size \* C-size = 5 \* 1 = 5</span></span>
- <span data-ttu-id="7f608-268">W-STRIDE = C-size = 1</span><span class="sxs-lookup"><span data-stu-id="7f608-268">W-stride = C-size = 1</span></span>
- <span data-ttu-id="7f608-269">C-STRIDE = 1</span><span class="sxs-lookup"><span data-stu-id="7f608-269">C-stride = 1</span></span>
- <span data-ttu-id="7f608-270">**DML_BUFFER_TENSOR_DESC:: Sizes** = {1, 1, 3, 5}</span><span class="sxs-lookup"><span data-stu-id="7f608-270">**DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, 3, 5 }</span></span>
- <span data-ttu-id="7f608-271">**DML_BUFFER_TENSOR_DESC:: progresos** = {15, 1, 5, 1}</span><span class="sxs-lookup"><span data-stu-id="7f608-271">**DML_BUFFER_TENSOR_DESC::Strides** = { 15, 1, 5, 1 }</span></span>

## <a name="see-also"></a><span data-ttu-id="7f608-272">Consulte también</span><span class="sxs-lookup"><span data-stu-id="7f608-272">See also</span></span>

* [<span data-ttu-id="7f608-273">Funciones auxiliares de DirectML</span><span class="sxs-lookup"><span data-stu-id="7f608-273">DirectML helper functions</span></span>](dml-helper-functions.md)
* [<span data-ttu-id="7f608-274">Estructura de DML_BUFFER_TENSOR_DESC</span><span class="sxs-lookup"><span data-stu-id="7f608-274">DML_BUFFER_TENSOR_DESC structure</span></span>](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc)
