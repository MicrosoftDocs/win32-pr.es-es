---
title: Introducción a DirectML
description: Direct Machine Learning (DirectML) es una API de bajo nivel para machine learning (ML).
ms.custom: Windows 10 May 2019 Update
ms.localizationpriority: high
ms.topic: article
ms.date: 04/19/2019
ms.openlocfilehash: 2dd37bc4c27364e26e4bbd4ae2cf5d43031c3314
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 09/16/2019
ms.locfileid: "74105111"
---
# <a name="introduction-to-directml"></a><span data-ttu-id="b41fa-103">Introducción a DirectML</span><span class="sxs-lookup"><span data-stu-id="b41fa-103">Introduction to DirectML</span></span>

## <a name="summary"></a><span data-ttu-id="b41fa-104">Resumen</span><span class="sxs-lookup"><span data-stu-id="b41fa-104">Summary</span></span>

<span data-ttu-id="b41fa-105">Direct Machine Learning (DirectML) es una API de bajo nivel para machine learning (ML).</span><span class="sxs-lookup"><span data-stu-id="b41fa-105">Direct Machine Learning (DirectML) is a low-level API for machine learning (ML).</span></span> <span data-ttu-id="b41fa-106">Los primitivos de machine learning con aceleración de hardware (denominados operadores) son los bloques de creación de DirectML.</span><span class="sxs-lookup"><span data-stu-id="b41fa-106">Hardware-accelerated machine learning primitives (called operators) are the building blocks of DirectML.</span></span> <span data-ttu-id="b41fa-107">A partir de estos bloques de creación, puede desarrollar dichas técnicas de aprendizaje automático como la escalabilidad, el suavizado de contorno y la transferencia de estilo, al nombre pero algunas.</span><span class="sxs-lookup"><span data-stu-id="b41fa-107">From those building blocks, you can develop such machine learning techniques as upscaling, anti-aliasing, and style transfer, to name but a few.</span></span> <span data-ttu-id="b41fa-108">Denoising y la superresolución, por ejemplo, le permiten lograr efectos raytraced impresionantes con menos rayos por píxel.</span><span class="sxs-lookup"><span data-stu-id="b41fa-108">Denoising and super-resolution, for example, allow you to achieve impressive raytraced effects with fewer rays per pixel.</span></span>

<span data-ttu-id="b41fa-109">Puede integrar las cargas de trabajo de inferencia del aprendizaje automático en su juego, motor, middleware, back-end u otra aplicación.</span><span class="sxs-lookup"><span data-stu-id="b41fa-109">You can integrate machine learning inferencing workloads into your game, engine, middleware, backend, or other application.</span></span> <span data-ttu-id="b41fa-110">DirectML tiene un flujo de trabajo y una interfaz de programación de estilo DirectX 12 (C++ nativo, nano-COM), y es compatible con todo el hardware compatible con DirectX 12.</span><span class="sxs-lookup"><span data-stu-id="b41fa-110">DirectML has a familiar (native C++, nano-COM) DirectX 12-style programming interface and workflow, and it's supported by all DirectX 12-compatible hardware.</span></span> <span data-ttu-id="b41fa-111">Para las aplicaciones de ejemplo de DirectML, incluido un ejemplo de una aplicación de DirectML mínima, vea [aplicaciones de ejemplo de DirectML](dml-min-app.md).</span><span class="sxs-lookup"><span data-stu-id="b41fa-111">For DirectML sample applications, including a sample of a minimal DirectML application, see [DirectML sample applications](dml-min-app.md).</span></span>

<span data-ttu-id="b41fa-112">DirectML se ha introducido en Windows 10, versión 1903 y en la versión correspondiente de la Windows SDK.</span><span class="sxs-lookup"><span data-stu-id="b41fa-112">DirectML is introduced in Windows 10, version 1903, and in the corresponding version of the Windows SDK.</span></span>

## <a name="is-directml-appropriate-for-my-project"></a><span data-ttu-id="b41fa-113">¿Es DirectML adecuado para mi proyecto?</span><span class="sxs-lookup"><span data-stu-id="b41fa-113">Is DirectML appropriate for my project?</span></span>

<span data-ttu-id="b41fa-114">DirectML es un componente de la paraguas [machine learning Windows](/windows/ai) .</span><span class="sxs-lookup"><span data-stu-id="b41fa-114">DirectML is a component under the [Windows Machine Learning](/windows/ai) umbrella.</span></span> <span data-ttu-id="b41fa-115">La API WinML de nivel superior se centra principalmente en el modelo, con su flujo de trabajo de carga-enlace-evaluación.</span><span class="sxs-lookup"><span data-stu-id="b41fa-115">The higher-level WinML API is primarily model-focused, with its load-bind-evaluate workflow.</span></span> <span data-ttu-id="b41fa-116">Pero los dominios como juegos y motores suelen necesitar un nivel inferior de abstracción y un mayor grado de control del desarrollador, con el fin de aprovechar al máximo el silicio.</span><span class="sxs-lookup"><span data-stu-id="b41fa-116">But domains such as games and engines typically need a lower level of abstraction, and a higher degree of developer control, in order to take full advantage of the silicon.</span></span> <span data-ttu-id="b41fa-117">Si va a contar los milisegundos y se consuman los tiempos de fotogramas, DirectML satisfará sus necesidades de aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="b41fa-117">If you're counting milliseconds, and squeezing frame times, then DirectML will meet your machine learning needs.</span></span>

<span data-ttu-id="b41fa-118">Para escenarios confiables en tiempo real, de alto rendimiento, de baja latencia y de restricción de recursos, use DirectML (en lugar de WinML).</span><span class="sxs-lookup"><span data-stu-id="b41fa-118">For reliable real-time, high-performance, low-latency, and/or resource-constrained scenarios, use DirectML (rather than WinML).</span></span> <span data-ttu-id="b41fa-119">Puede integrar DirectML directamente en el motor o la canalización de representación existentes.</span><span class="sxs-lookup"><span data-stu-id="b41fa-119">You can integrate DirectML directly into your existing engine or rendering pipeline.</span></span> <span data-ttu-id="b41fa-120">O bien, en un nivel superior para los marcos de aprendizaje automático y el middleware personalizados, DirectML puede proporcionar un back-end de alto rendimiento en Windows.</span><span class="sxs-lookup"><span data-stu-id="b41fa-120">Or, at a higher level for custom machine learning frameworks and middleware, DirectML can provide a high-performance backend on Windows.</span></span>

<span data-ttu-id="b41fa-121">WinML se implementa mediante DirectML como uno de sus back-ends.</span><span class="sxs-lookup"><span data-stu-id="b41fa-121">WinML is itself implemented using DirectML as one of its backends.</span></span>

## <a name="what-work-does-directml-do-and-what-work-must-i-do-as-the-developer"></a><span data-ttu-id="b41fa-122">Qué trabajo hace DirectML; ¿y qué trabajo *debo* hacer como desarrollador?</span><span class="sxs-lookup"><span data-stu-id="b41fa-122">What work does DirectML do; and what work must *I* do as the developer?</span></span>

<span data-ttu-id="b41fa-123">DirectML ejecuta de forma eficaz las capas individuales del modelo de inferencia en la GPU (o en núcleos de aceleración de AI, si existen).</span><span class="sxs-lookup"><span data-stu-id="b41fa-123">DirectML efficiently executes the individual layers of your inference model on the GPU (or on AI-acceleration cores, if present).</span></span> <span data-ttu-id="b41fa-124">Cada capa es un operador y DirectML proporciona una biblioteca de operadores primitivos de aprendizaje automático de bajo nivel y acelerados por hardware.</span><span class="sxs-lookup"><span data-stu-id="b41fa-124">Each layer is an operator, and DirectML provides you with a library of low-level, hardware-accelerated machine learning primitive operators.</span></span> <span data-ttu-id="b41fa-125">Estos operadores tienen optimizaciones específicas del hardware y específicas de la arquitectura diseñadas para ellos (más información sobre esto en la sección [¿por qué funciona DirectML?](#why-does-directml-perform-so-well)).</span><span class="sxs-lookup"><span data-stu-id="b41fa-125">These operators have hardware-specific and architecture-specific optimizations designed in to them (more on that in the section [Why does DirectML perform so well?](#why-does-directml-perform-so-well)).</span></span> <span data-ttu-id="b41fa-126">Al mismo tiempo, como desarrollador, verá una única interfaz independiente del proveedor para ejecutar esos operadores.</span><span class="sxs-lookup"><span data-stu-id="b41fa-126">At the same time, you as the developer see a single, vendor-agnostic interface for executing those operators.</span></span>

<span data-ttu-id="b41fa-127">La biblioteca de operadores de DirectML proporciona todas las operaciones habituales que se espera que puedan usarse en una carga de trabajo de machine learning.</span><span class="sxs-lookup"><span data-stu-id="b41fa-127">The library of operators in DirectML supplies all of the usual operations that you'd expect to be able to use in a machine learning workload.</span></span>

- <span data-ttu-id="b41fa-128">Operadores de activación, como **linear**, **ReLU**, **sigmoidea**, **tanh**, etc.</span><span class="sxs-lookup"><span data-stu-id="b41fa-128">Activation operators, such as **linear**, **ReLU**, **sigmoid**, **tanh**, and more.</span></span>
- <span data-ttu-id="b41fa-129">Operadores de tipo elemento, como **Add**, **exp**, **log**, **Max**, **min**, **Sub** y more.</span><span class="sxs-lookup"><span data-stu-id="b41fa-129">Element-wise operators, such as **add**, **exp**, **log**, **max**, **min**, **sub**, and more.</span></span>
- <span data-ttu-id="b41fa-130">Operadores de circunvolución, como la **circunvolución** 2D y 3D, etc.</span><span class="sxs-lookup"><span data-stu-id="b41fa-130">Convolution operators, such as 2D and 3D **convolution**, and more.</span></span>
- <span data-ttu-id="b41fa-131">Operadores de reducción, como **argmin**, **Average**, **L2**, **SUM**, etc.</span><span class="sxs-lookup"><span data-stu-id="b41fa-131">Reduction operators, such as **argmin**, **average**, **l2**, **sum**, and more.</span></span>
- <span data-ttu-id="b41fa-132">Operadores de agrupación, como **Average**, **LP** y **Max**.</span><span class="sxs-lookup"><span data-stu-id="b41fa-132">Pooling operators, such as **average**, **lp**, and **max**.</span></span>
- <span data-ttu-id="b41fa-133">Operadores de red neuronal (NN), como **GEMM**, **Gru**, **LSTM** y **RNN**.</span><span class="sxs-lookup"><span data-stu-id="b41fa-133">Neural network (NN) operators, such as **gemm**, **gru**, **lstm**, and **rnn**.</span></span>
- <span data-ttu-id="b41fa-134">Y muchas más.</span><span class="sxs-lookup"><span data-stu-id="b41fa-134">And many more.</span></span>

<span data-ttu-id="b41fa-135">Para obtener el máximo rendimiento y no pagar por lo que no se usa, DirectML coloca el control en sus manos como desarrollador sobre cómo se ejecuta la carga de trabajo de machine learning en el hardware.</span><span class="sxs-lookup"><span data-stu-id="b41fa-135">For maximal performance, and so that you don't pay for what you don't use, DirectML puts the control into your hands as a developer over how your machine learning workload is executed on the hardware.</span></span> <span data-ttu-id="b41fa-136">Averiguar qué operadores deben ejecutarse y cuándo, es responsabilidad suya del desarrollador.</span><span class="sxs-lookup"><span data-stu-id="b41fa-136">Figuring out which operators to execute, and when, is your responsibility as the developer.</span></span> <span data-ttu-id="b41fa-137">Entre las tareas que se dejan a su discreción se incluyen: transcribir el modelo; simplificar y optimizar las capas; cargas de carga; asignación de recursos, enlace, administración de memoria (al igual que con Direct3D 12); y la ejecución del gráfico.</span><span class="sxs-lookup"><span data-stu-id="b41fa-137">Tasks that are left to your discretion include: transcribing the model; simplifying and optimizing your layers; loading weights; resource allocation, binding, memory management (just as with Direct3D 12); and execution of the graph.</span></span>

<span data-ttu-id="b41fa-138">Puede conservar el conocimiento de alto nivel de los gráficos (puede codificar el modelo directamente o puede escribir su propio cargador de modelos).</span><span class="sxs-lookup"><span data-stu-id="b41fa-138">You retain high-level knowledge of your graphs (you can hard-code your model directly, or you can write your own model loader).</span></span> <span data-ttu-id="b41fa-139">Puede diseñar un modelo de escalado, por ejemplo, mediante el uso de varias capas para cada uno de los operadores de **muestreo**, **convolución**, **normalización** y **activación** .</span><span class="sxs-lookup"><span data-stu-id="b41fa-139">You might design an upscaling model, for example, using several layers each of **upsample**, **convolution**, **normalization**, and **activation** operators.</span></span> <span data-ttu-id="b41fa-140">Con esa familiaridad, la programación cuidadosa y la administración de barreras, puede extraer el mayor paralelismo y el rendimiento del hardware.</span><span class="sxs-lookup"><span data-stu-id="b41fa-140">With that familiarity, careful scheduling, and barrier management, you can extract the most parallelism and performance from the hardware.</span></span> <span data-ttu-id="b41fa-141">Si va a desarrollar un juego, la administración y el control de recursos cuidadosos sobre la programación le permite intercalar cargas de trabajo de aprendizaje automático y trabajos de representación tradicionales para saturar la GPU.</span><span class="sxs-lookup"><span data-stu-id="b41fa-141">If you're developing a game, then your careful resource management and control over scheduling enables you to interleave machine learning workloads and traditional rendering work in order to saturate the GPU.</span></span>

## <a name="whats-the-high-level-directml-workflow"></a><span data-ttu-id="b41fa-142">¿Cuál es el flujo de trabajo de DirectML de alto nivel?</span><span class="sxs-lookup"><span data-stu-id="b41fa-142">What's the high-level DirectML workflow?</span></span>

<span data-ttu-id="b41fa-143">Esta es la receta de alto nivel sobre cómo esperamos que se use DirectML.</span><span class="sxs-lookup"><span data-stu-id="b41fa-143">Here's the high-level recipe for how we expect DirectML to be used.</span></span> <span data-ttu-id="b41fa-144">En las dos fases principales de la inicialización y la ejecución, los trabajos se registran en las listas de comandos y, a continuación, se ejecutan en una cola.</span><span class="sxs-lookup"><span data-stu-id="b41fa-144">Within the two main phases of initialization and execution, you record work into command lists and then you execute them on a queue.</span></span>

### <a name="initialization"></a><span data-ttu-id="b41fa-145">Inicialización</span><span class="sxs-lookup"><span data-stu-id="b41fa-145">Initialization</span></span>

1. <span data-ttu-id="b41fa-146">Cree los recursos de Direct3D 12 &mdash; el dispositivo Direct3D 12, la cola de comandos, la lista de comandos y los recursos como los montones de descriptores.</span><span class="sxs-lookup"><span data-stu-id="b41fa-146">Create your Direct3D 12 resources&mdash;the Direct3D 12 device, command queue, command list, and resources such as descriptor heaps.</span></span>
2. <span data-ttu-id="b41fa-147">Dado que está realizando la inferencia de aprendizaje automático, así como la carga de trabajo de representación, cree los recursos de DirectML en &mdash; el dispositivo DirectML y en las instancias de operador.</span><span class="sxs-lookup"><span data-stu-id="b41fa-147">Since you're doing machine learning inferencing as well as your rendering workload, create DirectML resources&mdash;the DirectML device, and operator instances.</span></span> <span data-ttu-id="b41fa-148">Si tiene un modelo de aprendizaje automático en el que necesita realizar un tipo determinado de circunvolución con un tamaño determinado del filtro tensores con un tipo de datos determinado, todos ellos son todos los parámetros del operador de **convolución** de DirectML.</span><span class="sxs-lookup"><span data-stu-id="b41fa-148">If you have a machine learning model where you need to perform a particular type of convolution with a particular size of filter tensor with a particular data type, then those are all parameters into DirectML's **convolution** operator.</span></span>
3. <span data-ttu-id="b41fa-149">Los registros de DirectML funcionan en listas de comandos de Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="b41fa-149">DirectML records work into Direct3D 12 command lists.</span></span> <span data-ttu-id="b41fa-150">Por lo tanto, una vez que se realiza la inicialización, se registra el enlace y la inicialización de (por ejemplo) el operador de circunvolución en la lista de comandos.</span><span class="sxs-lookup"><span data-stu-id="b41fa-150">So, once initialization is done, you record the binding and initialization of (for example) your convolution operator into your command list.</span></span> <span data-ttu-id="b41fa-151">A continuación, cierre y ejecute la lista de comandos en la cola como de costumbre.</span><span class="sxs-lookup"><span data-stu-id="b41fa-151">Then, close and execute your command list on your queue as usual.</span></span>

### <a name="execution"></a><span data-ttu-id="b41fa-152">Ejecución</span><span class="sxs-lookup"><span data-stu-id="b41fa-152">Execution</span></span>

1. <span data-ttu-id="b41fa-153">Cargue los diez pesos en los recursos.</span><span class="sxs-lookup"><span data-stu-id="b41fa-153">Upload your weight tensors into resources.</span></span> <span data-ttu-id="b41fa-154">Un tensores de DirectML se representa mediante un recurso de Direct3D 12 normal.</span><span class="sxs-lookup"><span data-stu-id="b41fa-154">A tensor in DirectML is represented using a regular Direct3D 12 resource.</span></span> <span data-ttu-id="b41fa-155">Por ejemplo, si desea cargar los datos de peso en la GPU, hágalo de la misma forma que lo haría con cualquier otro recurso de Direct3D 12 (use un montón de carga o la cola de copia).</span><span class="sxs-lookup"><span data-stu-id="b41fa-155">For example, if you want to upload your weight data to the GPU, then you do that the same way you would with any other Direct3D 12 resource (use an upload heap, or the copy queue).</span></span>
2. <span data-ttu-id="b41fa-156">A continuación, debe enlazar esos recursos de Direct3D 12 como los de entrada y salida.</span><span class="sxs-lookup"><span data-stu-id="b41fa-156">Next, you need to bind those Direct3D 12 resources as your input and output tensors.</span></span> <span data-ttu-id="b41fa-157">Grabe en la lista de comandos el enlace y la ejecución de los operadores.</span><span class="sxs-lookup"><span data-stu-id="b41fa-157">Record into your command list the binding and the execution of your operators.</span></span>
3. <span data-ttu-id="b41fa-158">Cierre y ejecute la lista de comandos.</span><span class="sxs-lookup"><span data-stu-id="b41fa-158">Close and execute your command list.</span></span>

<span data-ttu-id="b41fa-159">Al igual que con Direct3D 12, la duración de los recursos y la sincronización son responsabilidad suya.</span><span class="sxs-lookup"><span data-stu-id="b41fa-159">Just as with Direct3D 12, resource lifetime and synchronization are your responsibility.</span></span> <span data-ttu-id="b41fa-160">Por ejemplo, no libere los objetos de DirectML al menos hasta que hayan finalizado la ejecución en la GPU.</span><span class="sxs-lookup"><span data-stu-id="b41fa-160">For example, don't release your DirectML objects at least until they've completed execution on the GPU.</span></span>

## <a name="why-does-directml-perform-so-well"></a><span data-ttu-id="b41fa-161">¿Por qué DirectML funciona tan bien?</span><span class="sxs-lookup"><span data-stu-id="b41fa-161">Why does DirectML perform so well?</span></span>

<span data-ttu-id="b41fa-162">Hay una buena razón por la que no debe escribir su propio operador de convolución (por ejemplo,) como HLSL en un [sombreador de cálculo](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span><span class="sxs-lookup"><span data-stu-id="b41fa-162">There's a good reason why you shouldn't just write your own convolution operator (for example) as HLSL in a [compute shader](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span></span> <span data-ttu-id="b41fa-163">La ventaja de usar DirectML es que, &mdash; además de ahorrarle el esfuerzo de homebrewing su propia solución, &mdash; tiene la capacidad de ofrecer un rendimiento mucho mejor que el que podría lograr con un sombreador de cálculo de uso general y escrito para algo como **circunvolución** o **LSTM**.</span><span class="sxs-lookup"><span data-stu-id="b41fa-163">The advantage of using DirectML is that&mdash;apart from saving you the effort of homebrewing your own solution&mdash;it has the capability of giving you much better performance than you could achieve with a hand-written, general-purpose compute shader for something like **convolution**, or **lstm**.</span></span>

<span data-ttu-id="b41fa-164">DirectML logra esto en parte debido a la característica de metacomandos de Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="b41fa-164">DirectML achieves this in part due to the Direct3D 12 metacommands feature.</span></span> <span data-ttu-id="b41fa-165">Los metacomandos exponen un cuadro negro de funcionalidad hasta DirectML, lo que permite a los proveedores de hardware proporcionar acceso DirectML a las optimizaciones específicas del hardware del proveedor y específicas de la arquitectura.</span><span class="sxs-lookup"><span data-stu-id="b41fa-165">Metacommands expose a black box of functionality up to DirectML, which allows hardware vendors to provide DirectML access to vendor hardware-specific and architecture-specific optimizations.</span></span> <span data-ttu-id="b41fa-166">Varios operadores &mdash; por ejemplo, convolución seguido de &mdash; la activación se pueden *fusionar* mediante combinación en un solo metacomando.</span><span class="sxs-lookup"><span data-stu-id="b41fa-166">Multiple operators&mdash;for example, convolution followed by activation&mdash;can be *fused* together into a single metacommand.</span></span> <span data-ttu-id="b41fa-167">Debido a estos factores, DirectML tiene la capacidad de superar el rendimiento de incluso un sombreador de cálculo totalmente escrito y optimizado para ejecutarse en una amplia gama de hardware.</span><span class="sxs-lookup"><span data-stu-id="b41fa-167">Because of these factors, DirectML has the capability to exceed the performance of even a very well-written hand-tuned compute shader written to run on a breadth of hardware.</span></span>

<span data-ttu-id="b41fa-168">Los metacomandos forman parte de la API de Direct3D 12, aunque están acoplados de forma flexible.</span><span class="sxs-lookup"><span data-stu-id="b41fa-168">Metacommands are part of the Direct3D 12 API, although they're loosely coupled to it.</span></span> <span data-ttu-id="b41fa-169">Un metacomando se identifica mediante un [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid)fijo, mientras que casi todo lo demás (desde su comportamiento y semántica hasta su firma y nombre) no forman parte estrictamente de la API de Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="b41fa-169">A metacommand is identified by a fixed [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid), while almost everything else about it (from its behavior and semantics to its signature and name) are not strictly part of the Direct3D 12 API.</span></span> <span data-ttu-id="b41fa-170">En su lugar, se especifica un metacomando entre su autor y el controlador que lo implementa.</span><span class="sxs-lookup"><span data-stu-id="b41fa-170">Rather, a metacommand is specified between its author and the driver that implements it.</span></span> <span data-ttu-id="b41fa-171">En este caso, el autor es DirectML.</span><span class="sxs-lookup"><span data-stu-id="b41fa-171">In this case, the author is DirectML.</span></span> <span data-ttu-id="b41fa-172">Los metacomandos son primitivos de Direct3D 12 (al igual que en el caso de las distribuciones y los envíos), para que se puedan grabar en una lista de comandos y estén programados para su ejecución.</span><span class="sxs-lookup"><span data-stu-id="b41fa-172">Metacommands are Direct3D 12 primitives (just like Draws and Dispatches), so they can be recorded into a command list and scheduled for execution together.</span></span>

<span data-ttu-id="b41fa-173">DirectML acelera las cargas de trabajo de aprendizaje automático con un conjunto completo de metacomandos de machine learning.</span><span class="sxs-lookup"><span data-stu-id="b41fa-173">DirectML accelerates your machine learning workloads using an entire suite of machine learning metacommands.</span></span> <span data-ttu-id="b41fa-174">Por lo tanto, no es necesario escribir rutas de acceso de código específicas del proveedor para lograr la aceleración de hardware para la inferencia.</span><span class="sxs-lookup"><span data-stu-id="b41fa-174">Consequently, you don't need to write vendor-specific code paths to achieve hardware acceleration for your inferencing.</span></span> <span data-ttu-id="b41fa-175">Si tiene que ejecutarse en un chip de inteligencia artificial, DirectML usa ese hardware para acelerar considerablemente las operaciones como la circunvolución.</span><span class="sxs-lookup"><span data-stu-id="b41fa-175">If you happen to run on an AI-accelerated chip, then DirectML uses that hardware to greatly accelerate operations such as convolution.</span></span> <span data-ttu-id="b41fa-176">Puede tomar el mismo código que ha escrito, sin modificarlo, ejecutarlo en un chip que no sea de inteligencia artificial (quizás la GPU integrada en el portátil) y seguir teniendo una excelente aceleración de hardware de GPU.</span><span class="sxs-lookup"><span data-stu-id="b41fa-176">You can take the same code that you wrote, without modifying it, run it on a chip that's not AI-accelerated (perhaps the integrated GPU in your laptop), and still get great GPU hardware acceleration.</span></span> <span data-ttu-id="b41fa-177">Y si no hay ninguna GPU disponible, DirectML recurre a la CPU.</span><span class="sxs-lookup"><span data-stu-id="b41fa-177">And if no GPU is available, then DirectML falls back to the CPU.</span></span>
